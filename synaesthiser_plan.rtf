{\rtf1\ansi\ansicpg1252\cocoartf2513
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Instruments\
\
Can be monophonic or polyphonic\
\
Notes\
\
Will have an instrument, if it is monophonic, it will just have a stage. If it is polyphonic, it probably needs a stage layer, unless there are other ways of blending\
\
An example of a monophonic instrument would be a \'91background\'92. This would be just an opaque bitmap. I guess it could have some \'91camera pathing\'92\
\
For initial implementation we\'92d be interested note_on velocity and note. Mod and aftertouch are out of scope. I think sustain pedal \
\
Could have the camera as the only active thing with the notes being passive data structures. Only when the camera takes a frame would the current notes generate output. Against this is needing to know how long the note has been active -easy enough- so that we know at what point in the process it is. This would remove the need for a stage.\
\
 OK what kind of note classes are we going to support?\
\
Bitmap (typically background, but could be puppet) note-off action is just to stop showing it (ie no \'91decay\'92 phase)\
Maybe have a \'91default\'92 image and any number of note-value-specific values. Initially no velocity sensitivity.\
\
Dollop and path. Show a vector dollop at a point on an (initially) linear path. Let\'92s start with a \'91falling\'92 blob where the x position is determined by the note value, the  Y position is related to the time from note_on. Just disappear on note off. Stretch, make size related to velocity. Mono or poly, whatever\'92s easier.\
\
On a note_on, a note is created as an instance of an instrument and placed in the hash of current notes indexed by note. If there\'92s already one (there shouldn\'92t be) it just gets replaced. When a note_off is received, the note is removed from the hash.\
\
At frame click time, the hash is scanned and appropriate images generated. \
\
User interface to allow the port to be associated with one of the two instrument types and to associate bitmap files with bitmap objects. Later there would be several parameters associated with dollops. Need a \'91start camera\'92 and \'91stop camera\'92\
\
Maybe allow the UI to specify a fixed background or \'91drone\'92\
\
Start with the bitmap instrument. Use the various horn-section bitmaps\
\
As we\'92re kind of vaguely considering pencil2d interaction, the default camera size is 800*600, Zooming the camera scales the bitmaps and vectors, but the output is still 800*600 (by default). The width and height can be independently changed to arbitrary values, not well-known presets. 800*600 has a 4:3 aspect ratio (or 16:12 if you prefer) certainly it\'92s more square than the usual ones. 800*450 would be 16:9.\
\
Standard 16:9 resolutions can be:\
\
3200 x 1800 (QHD+)\
2560\'d71440 (1440p, QHD)\
1920\'d71080 (1080p, FHD)\
1600\'d7900 (HD+)\
1366\'d7768 (WXGA)\
1280\'d7720 (720p, HD)\
960\'d7540 (qHD)\
720\'d7480 (480p, SD)\
\
As Pencil2d isn\'92t really wedded to any particular resolution or aspect ratio, it would be sensible to go for a 16:9, and let\'92s fix it at 960*540 for now.\
\
It\'92s important that this doesn\'92t become \'91just another midi visualiser\'92, but embodies the Nagro Amenic concept.\
\
A useful extra on bitmap instruments would be the concept of a rest image. This would apply only in monophonic mode and would show when there was no note. I *think* this implies the concept of a \'91voice\'92 that can either be singing or not. It would be useful to sometimes include a completely transparent (empty) bitmap on some note values, particularly if there was a rest image.\
\
Maybe a voice could change its instrument in response to a control_change control=93, which seems to be a patch select. It may be sysx, could look that up, but not a priority.\
\
Make ui, implement drone. implement viewer (how active does that need to be?). I guess if the viewer is going to be sizable it\'92s going to get more complex, but for now if we just way it is 960*540 that\'92ll remove a layer of scaling. And it\'92s an OK sort of size. In terms of image combination, I think it would be enough to just use PIL::Image.paste\
\
At some stage, we\'92d want to store midi performance data, but that\'92s a whole nother can of worms\
\
store the bitmaps in voice, not just fname\
do noteMap table row inserts/deletes\
Save and load voices list (?as json?)\
edit voices (look into menu bar)\
have scaling viewing for bitmaps with ability to apply same scalings to sets of bitmaps\
\
get voice edit to respond to midi note on\
https://docs.python.org/3/library/multiprocessing.html#exchanging-objects-between-processes\
\
Need to tighten terminology and it makes sense to fall in with midi terminology as it makes sense to store and load performance data in that format. Obviously a frame-assembler can\'92t work from events, it needs to know what is current now, and, for more subtle, pathed voices, it needs to know how long it\'92s been current. So we\'92ll have a \'92sound board\'92 which is a kind of whiteboard that is updated by performance events and is used by the camera to assemble the pics by referring to voice info.\
\
In midi terms, a voice is a patch. As patch is a fairly rubbish term, I think I\'92ll stick with voice. Channel makes sense, and I don\'92t think the 16-channel restriction should be too troublesome for now. In terms of layering, it may make sense for channel order to be significant.\
\
Paths\
\
A path is a function that expresses how a value will change in response to pitch, velocity or elapsed time since note on (and possibly note off)\
\
The output of the function could be used to control\
\
Xpos\
Ypos\
XScale\
YScale\
brightness\
hue\
opacity\
etc\
\
The function could be simple and linear or quite complex. It\'92s only maths after all and maths is cheap and quick. \
\
In addition to maths function paths, it would be possible to have \'91hand made\'92 map functions where the relationship between the input and the output is hand crafted. Essentially we\'92ve already got this with the mapping of note values to images.\
\
Exactly how the user expresses the maths functions is a bit more tricky. Something like \'91time elapsed since note on times two\'92 or \'91 sin of time elapsed\'92 \'97 possibly with some attenuating factor. \
\
Next step, I think to get bit.mid to \'91play\'92 a simple bitmap per note voice. so implement soundBoard, get player to write to it and camera to read it and display.\
\
What goes on soundBoard?\
\
Channel, start time, velocity, note\
\
What functions?\
\
stop all\
\
note on\
\
note off\
\
lock_board	causes all incoming events to just get queued rather than affecting the board\
unlock_board   adds all queued events to the board then unlocks\
\
Get active notes\
\
mapping of channels would be external to the soundboard\
\
The reader locks, not the writer\
\
The UI needs changing so that we have a 16 row map of channels to voices done in a similar way to the notemap. It should be a fairly easy development, but for now we\'92ll just go ahead with the \'91default voice\'92 being the channel 0 voice.\
\
However, there are changes required to the UI just to exercise the engine.\
\
select a performance file -doesn\'92t need a UI\
start camera and player -just needs a button\
\
Before I can iimplement merge, which flattens the layers into a frame, I need to have the images cached so add a qpixmap to imgtable when clicking the save button in the vedit or when loading an orchestra. But don\'92t save them with the orchestra. Well not for now anyway. Actually it\'92s a real faff NOT saving them, so for now we just save them. Sorry, it may be a faff but it\'92s necessary because you can\'92t json serialize a qpixmap\
\
\
\
\
\
}